{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utilities as UT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(LABEL_PATH ,TEST_NUM):\n",
    "    # This function is used to prepare train/test labels for 5-fold cross-validation\n",
    "    TEST_LABEL = LABEL_PATH + '/fold_' + str(TEST_NUM) +'.csv'\n",
    "\n",
    "    # combine train labels\n",
    "    filenames = [LABEL_PATH + '/fold_0.csv', \n",
    "                LABEL_PATH + '/fold_1.csv', \n",
    "                LABEL_PATH + '/fold_2.csv', \n",
    "                LABEL_PATH + '/fold_3.csv', \n",
    "                LABEL_PATH + '/fold_4.csv', ]\n",
    "\n",
    "    filenames.remove(TEST_LABEL)\n",
    "\n",
    "    with open(LABEL_PATH + '/combined_train_list.csv', 'w') as combined_train_list:\n",
    "        for fold in filenames:\n",
    "            for line in open(fold, 'r'):                \n",
    "                combined_train_list.write(line)\n",
    "    TRAIN_LABEL = LABEL_PATH + '/combined_train_list.csv'\n",
    "    \n",
    "    return TRAIN_LABEL, TEST_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Early_Fusion(Dataset):\n",
    "    def __init__(self, \n",
    "                 label_file='/data/scratch/gliang/data/adni/ADNI2_MRI/train_list.csv'):         \n",
    "        self.files = UT.read_csv(label_file)\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    def __getitem__(self,idx):\n",
    "        temp = self.files[idx]        \n",
    "        full_path = temp[0]        \n",
    "        \n",
    "        label = full_path.split('/')[-2]\n",
    "        if(label=='CN'):\n",
    "            label=0\n",
    "        elif(label=='AD'):\n",
    "            label=1\n",
    "        else:\n",
    "            print('Label Error')\n",
    "        \n",
    "        im = np.load(full_path) \n",
    "        im = np.reshape(im, (1,110,110,110))\n",
    "        return im, int(label), full_path # output image shape [T,C,W,H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm3d(inplanes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=3, stride=stride, padding=1)\n",
    "        self.conv2 = nn.Conv3d(planes, planes, kernel_size=3, stride=stride, padding=1)\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class ResNet3D(nn.Module):\n",
    "    def __init__(self, num_classes=2, input_shape=(1,110,110,110)): # input: input_shape:\t[num_of_filters, kernel_size] (e.g. [256, 25])\n",
    "        super(ResNet3D, self).__init__()\n",
    "        #stage 1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(\n",
    "            in_channels=input_shape[0],        \n",
    "            out_channels=32,       \n",
    "            kernel_size=(3,3,3),         \n",
    "            padding=1\n",
    "            ),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(\n",
    "            in_channels=32,       \n",
    "            out_channels=32,      \n",
    "            kernel_size=(3,3,3),          \n",
    "            padding=1              \n",
    "            ),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),                  \n",
    "            nn.Conv3d(\n",
    "            in_channels=32,       \n",
    "            out_channels=64,       \n",
    "            kernel_size=(3,3,3), \n",
    "            stride=2,\n",
    "            padding=1              \n",
    "            )\n",
    "        )\n",
    "        #stage 2\n",
    "        self.bot2=Bottleneck(64,64,1)\n",
    "        #stage 3\n",
    "        self.bot3=Bottleneck(64,64,1)\n",
    "        #stage 4\n",
    "        self.conv4=nn.Sequential(\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.Conv3d(\n",
    "            in_channels=64,        # input height\n",
    "            out_channels=64,       # n_filters\n",
    "            kernel_size=(3,3,3),          # filter size\n",
    "            padding=1,\n",
    "            stride=2\n",
    "            )\n",
    "        )\n",
    "        #stage 5\n",
    "        self.bot5=Bottleneck(64,64,1)\n",
    "        #stage 6\n",
    "        self.bot6=Bottleneck(64,64,1)\n",
    "        #stage 7\n",
    "        self.conv7=nn.Sequential(\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.Conv3d(\n",
    "            in_channels=64,        # input height\n",
    "            out_channels=128,       # n_filters\n",
    "            kernel_size=(3,3,3),          # filter size\n",
    "            padding=1,\n",
    "            stride=2\n",
    "            )\n",
    "        )\n",
    "        #stage 8\n",
    "        self.bot8=Bottleneck(128,128,1)\n",
    "        \n",
    "        #stage 9\n",
    "        self.bot9=Bottleneck(128,128,1)\n",
    "        \n",
    "        #stage 10\n",
    "        self.conv10=nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=(7,7,7)))\n",
    "        \n",
    "        fc1_output_features=128     \n",
    "        self.fc1 = nn.Sequential(\n",
    "             nn.Linear(1024, 128),\n",
    "             nn.ReLU()\n",
    "        )\n",
    "\n",
    "        fc2_output_features=2           \n",
    "        self.fc2 = nn.Sequential(\n",
    "        nn.Linear(fc1_output_features, fc2_output_features),\n",
    "        nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, drop_prob=0.8):\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)  \n",
    "        x = self.bot2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.bot3(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv4(x)\n",
    "        #print(x.shape) \n",
    "        x = self.bot5(x)\n",
    "        #print(x.shape)\n",
    "        x = self.bot6(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv7(x)\n",
    "        #print(x.shape)        \n",
    "        x = self.bot8(x)\n",
    "        #print(x.shape) \n",
    "        x = self.bot9(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv10(x)\n",
    "        #print(x.shape) \n",
    "        x = x.view(x.size(0), -1) # flatten the output of conv2 to (batch_size, num_filter * w * h)\n",
    "        #print(x.shape)        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        #prob = self.out(x) # probability\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_PATH = '/data/scratch/xxing/adni_dl/Preprocessed/ADNI2_MRI'\n",
    "\n",
    "GPU = 5\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 150\n",
    "\n",
    "LR = 0.0001\n",
    "LOSS_WEIGHTS = torch.tensor([1., 1.]) \n",
    "\n",
    "device = torch.device('cuda:'+str(GPU) if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, val_dataloader):\n",
    "    net = ResNet3D().to(device)\n",
    "    \n",
    "    #opt = torch.optim.Adam(net.parameters(), lr=LR, weight_decay=0.001)\n",
    "    opt = torch.optim.SGD(net.parameters(), lr=LR, momentum=0.9,nesterov=True)\n",
    "#   scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma= 0.985)\n",
    "#   scheduler = torch.optim.lr_scheduler.CyclicLR(opt, \n",
    "#                                                   base_lr=LR, \n",
    "#                                                   max_lr=0.001, \n",
    "#                                                   step_size_up=100,\n",
    "#                                                   cycle_momentum=False)\n",
    "    loss_fcn = torch.nn.CrossEntropyLoss(weight=LOSS_WEIGHTS.to(device))\n",
    "        \n",
    "    t = trange(EPOCHS, desc=' ', leave=True)\n",
    "\n",
    "    train_hist = []\n",
    "    val_hist = []\n",
    "    pred_result = []\n",
    "    old_acc = 0\n",
    "    test_acc = 0\n",
    "    best_epoch = 0\n",
    "    for e in t:    \n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        \n",
    "        val_y_true = []\n",
    "        val_y_pred = []                \n",
    "        \n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        # training\n",
    "        net.train()\n",
    "        for step, (img, label, _) in enumerate(train_dataloader):\n",
    "            img = img.float().to(device)\n",
    "            label = label.long().to(device)\n",
    "            opt.zero_grad()\n",
    "            out = net(img)\n",
    "            loss = loss_fcn(out, label)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            label = label.cpu().detach()\n",
    "            out = out.cpu().detach()\n",
    "            y_true, y_pred = UT.assemble_labels(step, y_true, y_pred, label, out)        \n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss = train_loss/(step+1)\n",
    "        acc = float(torch.sum(torch.max(y_pred, 1)[1]==y_true))/ float(len(y_pred))\n",
    "        auc = metrics.roc_auc_score(y_true, y_pred[:,1])\n",
    "        f1 = metrics.f1_score(y_true, torch.max(y_pred, 1)[1])\n",
    "        precision = metrics.precision_score(y_true, torch.max(y_pred, 1)[1])\n",
    "        recall = metrics.recall_score(y_true, torch.max(y_pred, 1)[1])\n",
    "        ap = metrics.average_precision_score(y_true, torch.max(y_pred, 1)[1]) #average_precision\n",
    "\n",
    "        #scheduler.step()\n",
    "\n",
    "        # val\n",
    "        net.eval()\n",
    "        full_path = []\n",
    "        with torch.no_grad():\n",
    "            for step, (img, label, _) in enumerate(val_dataloader):\n",
    "                img = img.float().to(device)\n",
    "                label = label.long().to(device)\n",
    "                out = net(img)\n",
    "                loss = loss_fcn(out, label)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                label = label.cpu().detach()\n",
    "                out = out.cpu().detach()\n",
    "                val_y_true, val_y_pred = UT.assemble_labels(step, val_y_true, val_y_pred, label, out)\n",
    "                \n",
    "                for item in _:\n",
    "                    full_path.append(item)\n",
    "                \n",
    "        val_loss = val_loss/(step+1)\n",
    "        val_acc = float(torch.sum(torch.max(val_y_pred, 1)[1]==val_y_true))/ float(len(val_y_pred))\n",
    "        val_auc = metrics.roc_auc_score(val_y_true, val_y_pred[:,1])\n",
    "        val_f1 = metrics.f1_score(val_y_true, torch.max(val_y_pred, 1)[1])\n",
    "        val_precision = metrics.precision_score(val_y_true, torch.max(val_y_pred, 1)[1])\n",
    "        val_recall = metrics.recall_score(val_y_true, torch.max(val_y_pred, 1)[1])\n",
    "        val_ap = metrics.average_precision_score(val_y_true, torch.max(val_y_pred, 1)[1]) #average_precision\n",
    "\n",
    "\n",
    "        train_hist.append([train_loss, acc, auc, f1, precision, recall, ap])\n",
    "        val_hist.append([val_loss, val_acc, val_auc, val_f1, val_precision, val_recall, val_ap])             \n",
    "\n",
    "        t.set_description(\"Epoch: %i, train loss: %.4f, train acc: %.4f, val loss: %.4f, val acc: %.4f, test acc: %.4f\" \n",
    "                          %(e, train_loss, acc, val_loss, val_acc, test_acc))\n",
    "\n",
    "\n",
    "        if(old_acc<val_acc):\n",
    "            old_acc = val_acc\n",
    "            best_epoch = e\n",
    "            test_loss = 0\n",
    "            test_y_true = val_y_true\n",
    "            test_y_pred = val_y_pred            \n",
    "\n",
    "            test_loss = val_loss\n",
    "            test_acc = float(torch.sum(torch.max(test_y_pred, 1)[1]==test_y_true))/ float(len(test_y_pred))\n",
    "            test_auc = metrics.roc_auc_score(test_y_true, test_y_pred[:,1])\n",
    "            test_f1 = metrics.f1_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_precision = metrics.precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_recall = metrics.recall_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_ap = metrics.average_precision_score(test_y_true, torch.max(test_y_pred, 1)[1]) #average_precision\n",
    "            \n",
    "        if(old_acc==val_acc) and (old_auc<val_auc):\n",
    "            old_acc = val_acc\n",
    "            old_auc = val_auc\n",
    "            best_epoch = e\n",
    "            test_loss = 0\n",
    "            test_y_true = val_y_true\n",
    "            test_y_pred = val_y_pred            \n",
    "\n",
    "            test_loss = val_loss\n",
    "            test_acc = float(torch.sum(torch.max(test_y_pred, 1)[1]==test_y_true))/ float(len(test_y_pred))\n",
    "            test_auc = metrics.roc_auc_score(test_y_true, test_y_pred[:,1])\n",
    "            test_f1 = metrics.f1_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_precision = metrics.precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_recall = metrics.recall_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_ap = metrics.average_precision_score(test_y_true, torch.max(test_y_pred, 1)[1]) #average_precision\n",
    "\n",
    "            \n",
    "            test_performance = [best_epoch, test_loss, test_acc, test_auc, test_f1, test_precision, test_recall, test_ap]\n",
    "\n",
    "    return train_hist, val_hist, test_performance, test_y_true, test_y_pred, full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = '/data/scratch/gliang/data/adni/ADNI2_MRI_Feature/Alex_Layer-9_DynamicImage'\n",
    "#FEATURE_SHAPE=(256,5,5)\n",
    "#print('DATA_PATH:',DATA_PATH)\n",
    "\n",
    "train_hist = []\n",
    "val_hist = []\n",
    "test_performance = []\n",
    "test_y_true = np.asarray([])\n",
    "test_y_pred = np.asarray([])\n",
    "full_path = np.asarray([])\n",
    "for i in range(0, 5):\n",
    "    print('Train Fold', i)\n",
    "    \n",
    "    TEST_NUM = i\n",
    "    TRAIN_LABEL, TEST_LABEL = prep_data(LABEL_PATH, TEST_NUM)\n",
    "    \n",
    "    train_dataset = Dataset_Early_Fusion(label_file=TRAIN_LABEL)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=1, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "\n",
    "    val_dataset = Dataset_Early_Fusion(label_file=TEST_LABEL)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, num_workers=1, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "        \n",
    "    cur_result = train(train_dataloader, val_dataloader)\n",
    "    \n",
    "    train_hist.append(cur_result[0])\n",
    "    val_hist.append(cur_result[1]) \n",
    "    test_performance.append(cur_result[2]) \n",
    "    test_y_true = np.concatenate((test_y_true, cur_result[3].numpy()))\n",
    "    if(len(test_y_pred) == 0):\n",
    "        test_y_pred = cur_result[4].numpy()\n",
    "    else:\n",
    "        test_y_pred = np.vstack((test_y_pred, cur_result[4].numpy()))\n",
    "    full_path = np.concatenate((full_path, np.asarray(cur_result[5])))\n",
    "    print('finish')\n",
    "\n",
    "print(test_performance)\n",
    "\n",
    "test_y_true = torch.tensor(test_y_true)\n",
    "test_y_pred = torch.tensor(test_y_pred)\n",
    "\n",
    "test_acc = float(torch.sum(torch.max(test_y_pred, 1)[1]==test_y_true.long()))/ float(len(test_y_pred))\n",
    "test_auc = metrics.roc_auc_score(test_y_true, test_y_pred[:,1])\n",
    "test_f1 = metrics.f1_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "test_precision = metrics.precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "test_recall = metrics.recall_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "test_ap = metrics.average_precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "\n",
    "print('ACC %.4f, AUC %.4f, F1 %.4f, Prec %.4f, Recall %.4f, AP %.4f' \n",
    "      %(test_acc, test_auc, test_f1, test_precision, test_recall, test_ap))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
