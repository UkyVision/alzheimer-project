{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utilities as UT\n",
    "from ranksvm import get_dynamic_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(LABEL_PATH ,TEST_NUM):\n",
    "    # This function is used to prepare train/test labels for 5-fold cross-validation\n",
    "    TEST_LABEL = LABEL_PATH + '/fold_' + str(TEST_NUM) +'.csv'\n",
    "\n",
    "    # combine train labels\n",
    "    filenames = [LABEL_PATH + '/fold_0.csv', \n",
    "                LABEL_PATH + '/fold_1.csv', \n",
    "                LABEL_PATH + '/fold_2.csv', \n",
    "                LABEL_PATH + '/fold_3.csv', \n",
    "                LABEL_PATH + '/fold_4.csv', ]\n",
    "\n",
    "    filenames.remove(TEST_LABEL)\n",
    "\n",
    "    with open(LABEL_PATH + '/combined_train_list.csv', 'w') as combined_train_list:\n",
    "        for fold in filenames:\n",
    "            for line in open(fold, 'r'):                \n",
    "                combined_train_list.write(line)\n",
    "    TRAIN_LABEL = LABEL_PATH + '/combined_train_list.csv'\n",
    "    \n",
    "    return TRAIN_LABEL, TEST_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Early_Fusion(Dataset):\n",
    "    def __init__(self, \n",
    "                 label_file='/data/scratch/xxing/adni_dl/Preprocessed/ADNI2_MRItrain_list.csv'):         \n",
    "        self.files = UT.read_csv(label_file)\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    def __getitem__(self,idx):\n",
    "        temp = self.files[idx]        \n",
    "        full_path = temp[0]        \n",
    "        \n",
    "        label = full_path.split('/')[-2]\n",
    "        if(label=='CN'):\n",
    "            label=0\n",
    "        elif(label=='AD'):\n",
    "            label=1\n",
    "        else:\n",
    "            print('Label Error')\n",
    "        \n",
    "        im = np.load(full_path) \n",
    "        im = get_dynamic_image(im)\n",
    "        im = np.expand_dims(im,0)\n",
    "        im = np.concatenate([im,im,im], 0)\n",
    "        \n",
    "        return im, int(label), full_path # output image shape [T,C,W,H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class att(nn.Module):\n",
    "    def __init__(self, input_channel):  \n",
    "        \"the soft attention module\"\n",
    "        super(att,self).__init__()\n",
    "        self.channel_in = input_channel\n",
    "    \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "            in_channels=input_channel,      \n",
    "            out_channels=512,    \n",
    "            kernel_size=1), \n",
    "            nn.ReLU()\n",
    "            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "            in_channels=512,      \n",
    "            out_channels=256,    \n",
    "            kernel_size=1), \n",
    "            nn.ReLU()\n",
    "            )\n",
    "        self.conv3 =nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "            in_channels=256,      \n",
    "            out_channels=64,    \n",
    "            kernel_size=1), \n",
    "            nn.ReLU()\n",
    "            )  \n",
    "        self.conv4 =nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "            in_channels=64,      \n",
    "            out_channels=1,    \n",
    "            kernel_size=1), \n",
    "            nn.Softmax(dim=2)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        mask = x\n",
    "        mask = self.conv1(mask)\n",
    "        mask = self.conv2(mask)\n",
    "        mask = self.conv3(mask)\n",
    "        att = self.conv4(mask)\n",
    "        #print(att.size())\n",
    "        output = torch.mul(x, att)\n",
    "        return output\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_classes=2, \n",
    "                 feature='Vgg11', \n",
    "                 feature_shape=(512,7,7),\n",
    "                 pretrained=True, \n",
    "                 requires_grad=False):         \n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Feature Extraction\n",
    "        if(feature=='Alex'):\n",
    "            self.ft_ext = models.alexnet(pretrained=pretrained) \n",
    "            self.ft_ext_modules = list(list(self.ft_ext.children())[:-2][0][:9])            \n",
    "            \n",
    "        elif(feature=='Res34'):\n",
    "            self.ft_ext = models.resnet34(pretrained=pretrained) \n",
    "            self.ft_ext_modules=list(self.ft_ext.children())[0:3]+list(self.ft_ext.children())[4:-2] # remove the Maxpooling layer\n",
    "            \n",
    "        elif(feature=='Res18'):\n",
    "            self.ft_ext = models.resnet18(pretrained=pretrained) \n",
    "            self.ft_ext_modules=list(self.ft_ext.children())[0:3]+list(self.ft_ext.children())[4:-2] # remove the Maxpooling layer\n",
    "            \n",
    "        elif(feature=='Vgg16'):\n",
    "            self.ft_ext = models.vgg16(pretrained=pretrained) \n",
    "            self.ft_ext_modules=list(self.ft_ext.children())[0][:30] # remove the Maxpooling layer\n",
    "            \n",
    "        elif(feature=='Vgg11'):\n",
    "            self.ft_ext = models.vgg11(pretrained=pretrained) \n",
    "            self.ft_ext_modules=list(self.ft_ext.children())[0][:19] # remove the Maxpooling layer\n",
    "            \n",
    "        elif(feature=='Mobile'):\n",
    "            self.ft_ext = models.mobilenet_v2(pretrained=pretrained) \n",
    "            self.ft_ext_modules=list(self.ft_ext.children())[0] # remove the Maxpooling layer\n",
    "            \n",
    "        self.ft_ext=nn.Sequential(*self.ft_ext_modules)                \n",
    "        for p in self.ft_ext.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "            \n",
    "        # Classifier\n",
    "        if(feature=='Alex'):\n",
    "            feature_shape=(256,5,5)\n",
    "        elif(feature=='Res34'):\n",
    "            feature_shape=(512,7,7)\n",
    "        elif(feature=='Res18'):\n",
    "            feature_shape=(512,7,7)\n",
    "        elif(feature=='Vgg16'):\n",
    "            feature_shape=(512,6,6)\n",
    "        elif(feature=='Vgg11'):\n",
    "            feature_shape=(512,6,6)\n",
    "        elif(feature=='Mobile'):\n",
    "            feature_shape=(1280,4,4)\n",
    "            \n",
    "        conv1_output_features = int(feature_shape[0])\n",
    "        \n",
    "        fc1_input_features = int(conv1_output_features*feature_shape[1]*feature_shape[2])\n",
    "        fc1_output_features = int(conv1_output_features*2)\n",
    "        fc2_output_features = int(fc1_output_features/4)\n",
    "        \n",
    "        self.attn=att(conv1_output_features)\n",
    "                \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=feature_shape[0],      \n",
    "                out_channels=conv1_output_features,    \n",
    "                kernel_size=1,       \n",
    "            ),\n",
    "            nn.BatchNorm2d(conv1_output_features),\n",
    "            nn.ReLU()\n",
    "        )                    \n",
    "        self.fc1 = nn.Sequential(\n",
    "             nn.Linear(fc1_input_features, fc1_output_features),\n",
    "             nn.BatchNorm1d(fc1_output_features),            \n",
    "             nn.ReLU()\n",
    "         )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "             nn.Linear(fc1_output_features, fc2_output_features),\n",
    "             nn.BatchNorm1d(fc2_output_features),\n",
    "             nn.ReLU()\n",
    "         )\n",
    "        \n",
    "        self.out = nn.Linear(fc2_output_features, num_classes)\n",
    "        \n",
    "    def forward(self, x, drop_prob=0.5):\n",
    "        x = self.ft_ext(x)\n",
    "        #print(x.size())\n",
    "        x= self.attn(x)\n",
    "        #x = self.conv1(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.fc1(x)\n",
    "        x = nn.Dropout(drop_prob)(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.Dropout(drop_prob)(x)        \n",
    "        prob = self.out(x) \n",
    "        \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, val_dataloader, feature='Vgg11'):\n",
    "    net = CNN(feature=feature).to(device)\n",
    "    \n",
    "    opt = torch.optim.Adam(net.parameters(), lr=LR, weight_decay=0.001)\n",
    "#     opt = torch.optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma= 0.985)\n",
    "#     scheduler = torch.optim.lr_scheduler.CyclicLR(opt, \n",
    "#                                                   base_lr=LR, \n",
    "#                                                   max_lr=0.001, \n",
    "#                                                   step_size_up=100,\n",
    "#                                                   cycle_momentum=False)\n",
    "    loss_fcn = torch.nn.CrossEntropyLoss(weight=LOSS_WEIGHTS.to(device))\n",
    "        \n",
    "    t = trange(EPOCHS, desc=' ', leave=True)\n",
    "\n",
    "    train_hist = []\n",
    "    val_hist = []\n",
    "    pred_result = []\n",
    "    old_acc = 0\n",
    "    old_auc = 0\n",
    "    test_acc = 0\n",
    "    best_epoch = 0\n",
    "    test_performance = []\n",
    "    for e in t:    \n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        \n",
    "        val_y_true = []\n",
    "        val_y_pred = []                \n",
    "        \n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        # training\n",
    "        net.train()\n",
    "        for step, (img, label, _) in enumerate(train_dataloader):\n",
    "            img = img.float().to(device)\n",
    "            label = label.long().to(device)\n",
    "            opt.zero_grad()\n",
    "            out = net(img)\n",
    "            loss = loss_fcn(out, label)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            label = label.cpu().detach()\n",
    "            out = out.cpu().detach()\n",
    "            y_true, y_pred = UT.assemble_labels(step, y_true, y_pred, label, out)        \n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss = train_loss/(step+1)\n",
    "        acc = float(torch.sum(torch.max(y_pred, 1)[1]==y_true))/ float(len(y_pred))\n",
    "        auc = metrics.roc_auc_score(y_true, y_pred[:,1])\n",
    "        f1 = metrics.f1_score(y_true, torch.max(y_pred, 1)[1])\n",
    "        precision = metrics.precision_score(y_true, torch.max(y_pred, 1)[1])\n",
    "        recall = metrics.recall_score(y_true, torch.max(y_pred, 1)[1])\n",
    "        ap = metrics.average_precision_score(y_true, torch.max(y_pred, 1)[1]) #average_precision\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # val\n",
    "        net.eval()\n",
    "        full_path = []\n",
    "        with torch.no_grad():\n",
    "            for step, (img, label, _) in enumerate(val_dataloader):\n",
    "                img = img.float().to(device)\n",
    "                label = label.long().to(device)\n",
    "                out = net(img)\n",
    "                loss = loss_fcn(out, label)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                label = label.cpu().detach()\n",
    "                out = out.cpu().detach()\n",
    "                val_y_true, val_y_pred = UT.assemble_labels(step, val_y_true, val_y_pred, label, out)\n",
    "                \n",
    "                for item in _:\n",
    "                    full_path.append(item)\n",
    "                \n",
    "        val_loss = val_loss/(step+1)\n",
    "        val_acc = float(torch.sum(torch.max(val_y_pred, 1)[1]==val_y_true))/ float(len(val_y_pred))\n",
    "        val_auc = metrics.roc_auc_score(val_y_true, val_y_pred[:,1])\n",
    "        val_f1 = metrics.f1_score(val_y_true, torch.max(val_y_pred, 1)[1])\n",
    "        val_precision = metrics.precision_score(val_y_true, torch.max(val_y_pred, 1)[1])\n",
    "        val_recall = metrics.recall_score(val_y_true, torch.max(val_y_pred, 1)[1])\n",
    "        val_ap = metrics.average_precision_score(val_y_true, torch.max(val_y_pred, 1)[1]) #average_precision\n",
    "\n",
    "\n",
    "        train_hist.append([train_loss, acc, auc, f1, precision, recall, ap])\n",
    "        val_hist.append([val_loss, val_acc, val_auc, val_f1, val_precision, val_recall, val_ap])             \n",
    "\n",
    "        t.set_description(\"Epoch: %i, train loss: %.4f, train acc: %.4f, val loss: %.4f, val acc: %.4f, test acc: %.4f\" \n",
    "                          %(e, train_loss, acc, val_loss, val_acc, test_acc))\n",
    "\n",
    "\n",
    "        if(old_acc<val_acc):\n",
    "            old_acc = val_acc\n",
    "            old_auc = val_auc\n",
    "            best_epoch = e\n",
    "            test_loss = 0\n",
    "            test_y_true = val_y_true\n",
    "            test_y_pred = val_y_pred            \n",
    "\n",
    "            test_loss = val_loss\n",
    "            test_acc = float(torch.sum(torch.max(test_y_pred, 1)[1]==test_y_true))/ float(len(test_y_pred))\n",
    "            test_auc = metrics.roc_auc_score(test_y_true, test_y_pred[:,1])\n",
    "            test_f1 = metrics.f1_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_precision = metrics.precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_recall = metrics.recall_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_ap = metrics.average_precision_score(test_y_true, torch.max(test_y_pred, 1)[1]) #average_precision\n",
    "\n",
    "            test_performance = [best_epoch, test_loss, test_acc, test_auc, test_f1, test_precision, test_recall, test_ap]\n",
    "        \n",
    "        if(old_acc==val_acc) and (old_auc<val_auc):\n",
    "            old_acc = val_acc\n",
    "            old_auc = val_auc\n",
    "            best_epoch = e\n",
    "            test_loss = 0\n",
    "            test_y_true = val_y_true\n",
    "            test_y_pred = val_y_pred            \n",
    "\n",
    "            test_loss = val_loss\n",
    "            test_acc = float(torch.sum(torch.max(test_y_pred, 1)[1]==test_y_true))/ float(len(test_y_pred))\n",
    "            test_auc = metrics.roc_auc_score(test_y_true, test_y_pred[:,1])\n",
    "            test_f1 = metrics.f1_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_precision = metrics.precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_recall = metrics.recall_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_ap = metrics.average_precision_score(test_y_true, torch.max(test_y_pred, 1)[1]) #average_precision\n",
    "\n",
    "            test_performance = [best_epoch, test_loss, test_acc, test_auc, test_f1, test_precision, test_recall, test_ap]\n",
    "    return train_hist, val_hist, test_performance, test_y_true, test_y_pred, full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_PATH = '/data/scratch/xxing/adni_dl/Preprocessed/ADNI2_MRI'\n",
    "\n",
    "GPU = 3\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 150\n",
    "\n",
    "LR = 0.0001\n",
    "LOSS_WEIGHTS = torch.tensor([1., 1.]) \n",
    "\n",
    "device = torch.device('cuda:'+str(GPU) if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 149, train loss: 0.0119, train acc: 1.0000, val loss: 1.0106, val acc: 0.6087, test acc: 0.7391: 100%|██████████| 150/150 [06:53<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 33, train loss: 0.3161, train acc: 0.9639, val loss: 0.6921, val acc: 0.5882, test acc: 0.8824:  23%|██▎       | 34/150 [01:30<04:57,  2.56s/it]/home/xxing/anaconda3/envs/myenv3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/xxing/anaconda3/envs/myenv3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Epoch: 34, train loss: 0.2240, train acc: 0.9157, val loss: 1.5689, val acc: 0.5294, test acc: 0.8824:  23%|██▎       | 35/150 [01:32<04:54,  2.56s/it]/home/xxing/anaconda3/envs/myenv3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/xxing/anaconda3/envs/myenv3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Epoch: 149, train loss: 0.1654, train acc: 0.9639, val loss: 0.2534, val acc: 0.7647, test acc: 1.0000: 100%|██████████| 150/150 [06:44<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss: 0.7213, train acc: 0.5732, val loss: 1.9562, val acc: 0.5000, test acc: 0.6111:   1%|▏         | 2/150 [00:05<06:47,  2.75s/it]/home/xxing/anaconda3/envs/myenv3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/xxing/anaconda3/envs/myenv3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Epoch: 2, train loss: 0.6472, train acc: 0.6463, val loss: 2.0274, val acc: 0.5556, test acc: 0.6111:   2%|▏         | 3/150 [00:08<06:37,  2.70s/it]/home/xxing/anaconda3/envs/myenv3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/xxing/anaconda3/envs/myenv3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Epoch: 149, train loss: 0.4540, train acc: 0.8659, val loss: 0.4339, val acc: 0.6111, test acc: 0.8333: 100%|██████████| 150/150 [06:46<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 149, train loss: 0.0336, train acc: 1.0000, val loss: 0.5678, val acc: 0.7143, test acc: 0.8929: 100%|██████████| 150/150 [06:57<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 31, train loss: 0.1882, train acc: 0.9419, val loss: 1.4281, val acc: 0.6429, test acc: 0.9286:  21%|██▏       | 32/150 [01:27<05:19,  2.71s/it]/home/xxing/anaconda3/envs/myenv3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/xxing/anaconda3/envs/myenv3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Epoch: 149, train loss: 0.0319, train acc: 1.0000, val loss: 0.9059, val acc: 0.6429, test acc: 0.9286: 100%|██████████| 150/150 [06:54<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115, 0.7638657465577126, 0.7391304347826086, 0.6428571428571428, 0.7999999999999999, 0.75, 0.8571428571428571, 0.7298136645962733], [114, 0.07645551860332489, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [63, 0.3206184506416321, 0.8333333333333334, 0.9125000000000001, 0.7999999999999999, 0.8571428571428571, 0.75, 0.753968253968254], [76, 0.5696732699871063, 0.8928571428571429, 0.8333333333333333, 0.8421052631578948, 0.8888888888888888, 0.8, 0.7825396825396825], [29, 0.47631120681762695, 0.9285714285714286, 0.7777777777777778, 0.9473684210526316, 0.9, 1.0, 0.9]]\n",
      "ACC 0.8700, AUC 0.8495, F1 0.8687, Prec 0.8600, Recall 0.8776, AP 0.8147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#DATA_PATH = '/data/scratch/gliang/data/adni/ADNI2_MRI_Feature/Alex_Layer-9_DynamicImage'\n",
    "#FEATURE_SHAPE=(256,5,5)\n",
    "#print('DATA_PATH:',DATA_PATH)\n",
    "\n",
    "train_hist = []\n",
    "val_hist = []\n",
    "test_performance = []\n",
    "test_y_true = np.asarray([])\n",
    "test_y_pred = np.asarray([])\n",
    "full_path = np.asarray([])\n",
    "for i in range(0, 5):\n",
    "    print('Train Fold', i)\n",
    "    \n",
    "    TEST_NUM = i\n",
    "    TRAIN_LABEL, TEST_LABEL = prep_data(LABEL_PATH, TEST_NUM)\n",
    "    \n",
    "    train_dataset = Dataset_Early_Fusion(label_file=TRAIN_LABEL)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=1, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "\n",
    "    val_dataset = Dataset_Early_Fusion(label_file=TEST_LABEL)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, num_workers=1, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "        \n",
    "    cur_result = train(train_dataloader, val_dataloader)\n",
    "    \n",
    "    train_hist.append(cur_result[0])\n",
    "    val_hist.append(cur_result[1]) \n",
    "    test_performance.append(cur_result[2]) \n",
    "    test_y_true = np.concatenate((test_y_true, cur_result[3].numpy()))\n",
    "    if(len(test_y_pred) == 0):\n",
    "        test_y_pred = cur_result[4].numpy()\n",
    "    else:\n",
    "        test_y_pred = np.vstack((test_y_pred, cur_result[4].numpy()))\n",
    "    full_path = np.concatenate((full_path, np.asarray(cur_result[5])))\n",
    "\n",
    "print(test_performance)\n",
    "\n",
    "test_y_true = torch.tensor(test_y_true)\n",
    "test_y_pred = torch.tensor(test_y_pred)\n",
    "test_acc = float(torch.sum(torch.max(test_y_pred, 1)[1]==test_y_true.long()))/ float(len(test_y_pred))\n",
    "test_auc = metrics.roc_auc_score(test_y_true, test_y_pred[:,1])\n",
    "test_f1 = metrics.f1_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "test_precision = metrics.precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "test_recall = metrics.recall_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "test_ap = metrics.average_precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "\n",
    "print('ACC %.4f, AUC %.4f, F1 %.4f, Prec %.4f, Recall %.4f, AP %.4f' \n",
    "      %(test_acc, test_auc, test_f1, test_precision, test_recall, test_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
