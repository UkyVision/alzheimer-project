{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utilities as UT\n",
    "from ranksvm import get_dynamic_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(LABEL_PATH ,TEST_NUM):\n",
    "    # This function is used to prepare train/test labels for 5-fold cross-validation\n",
    "    TEST_LABEL = LABEL_PATH + '/fold_' + str(TEST_NUM) +'.csv'\n",
    "\n",
    "    # combine train labels\n",
    "    filenames = [LABEL_PATH + '/fold_0.csv', \n",
    "                LABEL_PATH + '/fold_1.csv', \n",
    "                LABEL_PATH + '/fold_2.csv', \n",
    "                LABEL_PATH + '/fold_3.csv', \n",
    "                LABEL_PATH + '/fold_4.csv', ]\n",
    "\n",
    "    filenames.remove(TEST_LABEL)\n",
    "\n",
    "    with open(LABEL_PATH + '/combined_train_list.csv', 'w') as combined_train_list:\n",
    "        for fold in filenames:\n",
    "            for line in open(fold, 'r'):                \n",
    "                combined_train_list.write(line)\n",
    "    TRAIN_LABEL = LABEL_PATH + '/combined_train_list.csv'\n",
    "    \n",
    "    return TRAIN_LABEL, TEST_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Early_Fusion(Dataset):\n",
    "    def __init__(self, \n",
    "                 label_file='/data/scratch/xxing/adni_dl/Preprocessed/ADNI2_MRItrain_list.csv'):         \n",
    "        self.files = UT.read_csv(label_file)\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    def __getitem__(self,idx):\n",
    "        temp = self.files[idx]        \n",
    "        full_path = temp[0]        \n",
    "        \n",
    "        label = full_path.split('/')[-2]\n",
    "        if(label=='CN'):\n",
    "            label=0\n",
    "        elif(label=='AD'):\n",
    "            label=1\n",
    "        else:\n",
    "            print('Label Error')\n",
    "        \n",
    "        im = np.load(full_path) \n",
    "        im = np.transpose(im, (3,2,0,1))\n",
    "        \n",
    "        #im = get_dynamic_image(im)\n",
    "        #im = np.expand_dims(im,0)\n",
    "        #im = np.concatenate([im,im,im], 0)\n",
    "        \n",
    "        return im, int(label), full_path # output image shape [T,C,W,H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class att(nn.Module):\n",
    "    def __init__(self, input_channel):  \n",
    "        \"the soft attention module\"\n",
    "        super(att,self).__init__()\n",
    "        self.channel_in = input_channel\n",
    "    \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "            in_channels=input_channel,      \n",
    "            out_channels=512,    \n",
    "            kernel_size=1), \n",
    "            nn.ReLU()\n",
    "            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "            in_channels=512,      \n",
    "            out_channels=256,    \n",
    "            kernel_size=1), \n",
    "            nn.ReLU()\n",
    "            )\n",
    "        self.conv3 =nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "            in_channels=256,      \n",
    "            out_channels=64,    \n",
    "            kernel_size=1), \n",
    "            nn.ReLU()\n",
    "            )  \n",
    "        self.conv4 =nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "            in_channels=64,      \n",
    "            out_channels=1,    \n",
    "            kernel_size=1), \n",
    "            nn.Softmax(dim=2)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        mask = x\n",
    "        mask = self.conv1(mask)\n",
    "        mask = self.conv2(mask)\n",
    "        mask = self.conv3(mask)\n",
    "        att = self.conv4(mask)\n",
    "        #print(att.size())\n",
    "        output = torch.mul(x, att)\n",
    "        return output\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_classes=2, \n",
    "                 feature='Alex', \n",
    "                 feature_shape=(512,7,7),\n",
    "                 pretrained=True, \n",
    "                 requires_grad=True):         \n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        #max_pooling\n",
    "        self.maxpooling= nn.MaxPool3d((110, 1, 1), stride=(1, 1, 1))\n",
    "        \n",
    "        # Feature Extraction\n",
    "        if(feature=='Alex'):\n",
    "            self.ft_ext = models.alexnet(pretrained=pretrained) \n",
    "            self.ft_ext_modules = list(list(self.ft_ext.children())[:-2][0][:9])            \n",
    "            \n",
    "        elif(feature=='Res34'):\n",
    "            self.ft_ext = models.resnet34(pretrained=pretrained) \n",
    "            self.ft_ext_modules=list(self.ft_ext.children())[0:3]+list(self.ft_ext.children())[4:-2] # remove the Maxpooling layer\n",
    "            \n",
    "        elif(feature=='Res18'):\n",
    "            self.ft_ext = models.resnet18(pretrained=pretrained) \n",
    "            self.ft_ext_modules=list(self.ft_ext.children())[0:3]+list(self.ft_ext.children())[4:-2] # remove the Maxpooling layer\n",
    "            \n",
    "        elif(feature=='Vgg16'):\n",
    "            self.ft_ext = models.vgg16(pretrained=pretrained) \n",
    "            self.ft_ext_modules=list(self.ft_ext.children())[0][:30] # remove the Maxpooling layer\n",
    "            \n",
    "        elif(feature=='Vgg11'):\n",
    "            self.ft_ext = models.vgg11(pretrained=pretrained) \n",
    "            self.ft_ext_modules=list(self.ft_ext.children())[0][:19] # remove the Maxpooling layer\n",
    "            \n",
    "        elif(feature=='Mobile'):\n",
    "            self.ft_ext = models.mobilenet_v2(pretrained=pretrained) \n",
    "            self.ft_ext_modules=list(self.ft_ext.children())[0] # remove the Maxpooling layer\n",
    "            \n",
    "        self.ft_ext=nn.Sequential(*self.ft_ext_modules)                \n",
    "        for p in self.ft_ext.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "            \n",
    "        # Classifier\n",
    "        if(feature=='Alex'):\n",
    "            feature_shape=(256,5,5)\n",
    "        elif(feature=='Res34'):\n",
    "            feature_shape=(512,7,7)\n",
    "        elif(feature=='Res18'):\n",
    "            feature_shape=(512,7,7)\n",
    "        elif(feature=='Vgg16'):\n",
    "            feature_shape=(512,6,6)\n",
    "        elif(feature=='Vgg11'):\n",
    "            feature_shape=(512,6,6)\n",
    "        elif(feature=='Mobile'):\n",
    "            feature_shape=(1280,4,4)\n",
    "            \n",
    "        conv1_output_features = int(feature_shape[0])\n",
    "        \n",
    "        fc1_input_features = int(conv1_output_features*feature_shape[1]*feature_shape[2])\n",
    "        fc1_output_features = int(conv1_output_features*2)\n",
    "        fc2_output_features = int(fc1_output_features/4)\n",
    "        \n",
    "        self.attn=att(conv1_output_features)\n",
    "                \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=feature_shape[0],      \n",
    "                out_channels=conv1_output_features,    \n",
    "                kernel_size=1,       \n",
    "            ),\n",
    "            nn.BatchNorm2d(conv1_output_features),\n",
    "            nn.ReLU()\n",
    "        )                    \n",
    "        self.fc1 = nn.Sequential(\n",
    "             nn.Linear(fc1_input_features, fc1_output_features),\n",
    "             nn.BatchNorm1d(fc1_output_features),            \n",
    "             nn.ReLU()\n",
    "         )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "             nn.Linear(fc1_output_features, fc2_output_features),\n",
    "             nn.BatchNorm1d(fc2_output_features),\n",
    "             nn.ReLU()\n",
    "         )\n",
    "        \n",
    "        self.out = nn.Linear(fc2_output_features, num_classes)\n",
    "        \n",
    "    def forward(self, x, drop_prob=0.5):\n",
    "        x=self.maxpooling(x)\n",
    "        \n",
    "        x=x.repeat(1,3,1,1,1)\n",
    "        x=torch.squeeze(x, 2)\n",
    "        x = self.ft_ext(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        x= self.attn(x)\n",
    "        #x = self.conv1(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.fc1(x)\n",
    "        x = nn.Dropout(drop_prob)(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.Dropout(drop_prob)(x)        \n",
    "        prob = self.out(x) \n",
    "        \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, val_dataloader, feature='Vgg11'):\n",
    "    net = CNN(feature=feature).to(device)\n",
    "    \n",
    "    opt = torch.optim.Adam(net.parameters(), lr=LR, weight_decay=0.001)\n",
    "#     opt = torch.optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma= 0.985)\n",
    "#     scheduler = torch.optim.lr_scheduler.CyclicLR(opt, \n",
    "#                                                   base_lr=LR, \n",
    "#                                                   max_lr=0.001, \n",
    "#                                                   step_size_up=100,\n",
    "#                                                   cycle_momentum=False)\n",
    "    loss_fcn = torch.nn.CrossEntropyLoss(weight=LOSS_WEIGHTS.to(device))\n",
    "        \n",
    "    t = trange(EPOCHS, desc=' ', leave=True)\n",
    "\n",
    "    train_hist = []\n",
    "    test_hist = []\n",
    "    val_hist = []\n",
    "    pred_result = []\n",
    "    test_performance = []\n",
    "    old_acc = 0\n",
    "    old_auc = 0\n",
    "    test_acc = 0\n",
    "    best_epoch = 0\n",
    "    for e in t:    \n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        \n",
    "        val_y_true = []\n",
    "        val_y_pred = []                \n",
    "        \n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        # training\n",
    "        net.train()\n",
    "        for step, (img, label, _) in enumerate(train_dataloader):\n",
    "            img = img.float().to(device)\n",
    "            label = label.long().to(device)\n",
    "            opt.zero_grad()\n",
    "            out = net(img)\n",
    "            loss = loss_fcn(out, label)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            label = label.cpu().detach()\n",
    "            out = out.cpu().detach()\n",
    "            y_true, y_pred = UT.assemble_labels(step, y_true, y_pred, label, out)        \n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss = train_loss/(step+1)\n",
    "        acc = float(torch.sum(torch.max(y_pred, 1)[1]==y_true))/ float(len(y_pred))\n",
    "        auc = metrics.roc_auc_score(y_true, y_pred[:,1])\n",
    "        f1 = metrics.f1_score(y_true, torch.max(y_pred, 1)[1])\n",
    "        precision = metrics.precision_score(y_true, torch.max(y_pred, 1)[1])\n",
    "        recall = metrics.recall_score(y_true, torch.max(y_pred, 1)[1])\n",
    "        ap = metrics.average_precision_score(y_true, torch.max(y_pred, 1)[1]) #average_precision\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # val\n",
    "        net.eval()\n",
    "        full_path = []\n",
    "        with torch.no_grad():\n",
    "            for step, (img, label, _) in enumerate(val_dataloader):\n",
    "                img = img.float().to(device)\n",
    "                label = label.long().to(device)\n",
    "                out = net(img)\n",
    "                loss = loss_fcn(out, label)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                label = label.cpu().detach()\n",
    "                out = out.cpu().detach()\n",
    "                val_y_true, val_y_pred = UT.assemble_labels(step, val_y_true, val_y_pred, label, out)\n",
    "                \n",
    "                for item in _:\n",
    "                    full_path.append(item)\n",
    "                \n",
    "        val_loss = val_loss/(step+1)\n",
    "        val_acc = float(torch.sum(torch.max(val_y_pred, 1)[1]==val_y_true))/ float(len(val_y_pred))\n",
    "        val_auc = metrics.roc_auc_score(val_y_true, val_y_pred[:,1])\n",
    "        val_f1 = metrics.f1_score(val_y_true, torch.max(val_y_pred, 1)[1])\n",
    "        val_precision = metrics.precision_score(val_y_true, torch.max(val_y_pred, 1)[1])\n",
    "        val_recall = metrics.recall_score(val_y_true, torch.max(val_y_pred, 1)[1])\n",
    "        val_ap = metrics.average_precision_score(val_y_true, torch.max(val_y_pred, 1)[1]) #average_precision\n",
    "\n",
    "\n",
    "        train_hist.append([train_loss, acc, auc, f1, precision, recall, ap])\n",
    "        val_hist.append([val_loss, val_acc, val_auc, val_f1, val_precision, val_recall, val_ap])             \n",
    "\n",
    "        t.set_description(\"Epoch: %i, train loss: %.4f, train acc: %.4f, val loss: %.4f, val acc: %.4f, test acc: %.4f\" \n",
    "                          %(e, train_loss, acc, val_loss, val_acc, test_acc))\n",
    "\n",
    "\n",
    "        if(old_acc<val_acc):\n",
    "            old_acc = val_acc\n",
    "            old_auc = val_auc\n",
    "            best_epoch = e\n",
    "            test_loss = 0\n",
    "            test_y_true = val_y_true\n",
    "            test_y_pred = val_y_pred            \n",
    "\n",
    "            test_loss = val_loss\n",
    "            test_acc = float(torch.sum(torch.max(test_y_pred, 1)[1]==test_y_true))/ float(len(test_y_pred))\n",
    "            test_auc = metrics.roc_auc_score(test_y_true, test_y_pred[:,1])\n",
    "            test_f1 = metrics.f1_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_precision = metrics.precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_recall = metrics.recall_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_ap = metrics.average_precision_score(test_y_true, torch.max(test_y_pred, 1)[1]) #average_precision\n",
    "\n",
    "            test_performance = [best_epoch, test_loss, test_acc, test_auc, test_f1, test_precision, test_recall, test_ap]\n",
    "        \n",
    "        if(old_acc==val_acc) and (old_auc<val_auc):\n",
    "            old_acc = val_acc\n",
    "            old_auc = val_auc\n",
    "            best_epoch = e\n",
    "            test_loss = 0\n",
    "            test_y_true = val_y_true\n",
    "            test_y_pred = val_y_pred            \n",
    "\n",
    "            test_loss = val_loss\n",
    "            test_acc = float(torch.sum(torch.max(test_y_pred, 1)[1]==test_y_true))/ float(len(test_y_pred))\n",
    "            test_auc = metrics.roc_auc_score(test_y_true, test_y_pred[:,1])\n",
    "            test_f1 = metrics.f1_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_precision = metrics.precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_recall = metrics.recall_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "            test_ap = metrics.average_precision_score(test_y_true, torch.max(test_y_pred, 1)[1]) #average_precision\n",
    "\n",
    "            test_performance = [best_epoch, test_loss, test_acc, test_auc, test_f1, test_precision, test_recall, test_ap]\n",
    "    return train_hist, val_hist, test_performance, test_y_true, test_y_pred, full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_PATH = '/data/scratch/xxing/adni_dl/Preprocessed/ADNI2_MRI'\n",
    "\n",
    "GPU = 6\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 150\n",
    "\n",
    "LR = 0.0001\n",
    "LOSS_WEIGHTS = torch.tensor([1., 1.]) \n",
    "\n",
    "device = torch.device('cuda:'+str(GPU) if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('DATA_PATH:',DATA_PATH)\n",
    "\n",
    "train_hist = []\n",
    "val_hist = []\n",
    "test_performance = []\n",
    "test_y_true = np.asarray([])\n",
    "test_y_pred = np.asarray([])\n",
    "full_path = np.asarray([])\n",
    "for i in range(0, 5):\n",
    "    print('Train Fold', i)\n",
    "    \n",
    "    TEST_NUM = i\n",
    "    TRAIN_LABEL, TEST_LABEL = prep_data(LABEL_PATH, TEST_NUM)\n",
    "    \n",
    "    train_dataset = Dataset_Early_Fusion(label_file=TRAIN_LABEL)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=1, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "\n",
    "    val_dataset = Dataset_Early_Fusion(label_file=TEST_LABEL)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, num_workers=1, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "        \n",
    "    cur_result = train(train_dataloader, val_dataloader)\n",
    "    \n",
    "    train_hist.append(cur_result[0])\n",
    "    val_hist.append(cur_result[1]) \n",
    "    test_performance.append(cur_result[2]) \n",
    "    test_y_true = np.concatenate((test_y_true, cur_result[3].numpy()))\n",
    "    if(len(test_y_pred) == 0):\n",
    "        test_y_pred = cur_result[4].numpy()\n",
    "    else:\n",
    "        test_y_pred = np.vstack((test_y_pred, cur_result[4].numpy()))\n",
    "    full_path = np.concatenate((full_path, np.asarray(cur_result[5])))\n",
    "\n",
    "print(test_performance)\n",
    "\n",
    "test_y_true = torch.tensor(test_y_true)\n",
    "test_y_pred = torch.tensor(test_y_pred)\n",
    "test_acc = float(torch.sum(torch.max(test_y_pred, 1)[1]==test_y_true.long()))/ float(len(test_y_pred))\n",
    "test_auc = metrics.roc_auc_score(test_y_true, test_y_pred[:,1])\n",
    "test_f1 = metrics.f1_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "test_precision = metrics.precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "test_recall = metrics.recall_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "test_ap = metrics.average_precision_score(test_y_true, torch.max(test_y_pred, 1)[1])\n",
    "\n",
    "print('ACC %.4f, AUC %.4f, F1 %.4f, Prec %.4f, Recall %.4f, AP %.4f' \n",
    "      %(test_acc, test_auc, test_f1, test_precision, test_recall, test_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=np.load('/data/scratch/xxing/adni_dl/Preprocessed/ADNI2_MRI/AD/021_S_4924.npy')\n",
    "#data=np.transpose(data,(3,2,0,1))\n",
    "#plt.imshow(data[0,55,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
